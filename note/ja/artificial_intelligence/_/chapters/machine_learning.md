# 『機械学習』ノート

（最終更新： 2023-05-07）


## 目次

1. [機械学習](#機械学習)
	1. [学習モデル](#学習モデル)
	1. [パラメータ](#パラメータ)
	1. [チューニング](#チューニング)
	1. [特徴量](#特徴量)
	1. [学習率](#学習率)
	1. [汎化性能](#汎化性能)
	1. [重み](#重み)
	1. [バイアス](#バイアス)
	1. [分類](#分類)
	1. [回帰](#回帰)
	1. [クラス](#クラス)
1. [教師あり学習](#教師あり学習)
	1. [ラベル](#ラベル)
	1. [ラベル付きデータ](#ラベル付きデータ)
	1. [ラベリング](#ラベリング)
1. [教師なし学習](#教師なし学習)
	1. [クラスタリング](#クラスタリング)
	1. [階層的クラスタリング](#階層的クラスタリング)
	1. [非階層的クラスタリング](#非階層的クラスタリング)
	1. [次元削減](#次元削減)
	1. [次元の呪い](#次元の呪い)
1. [強化学習](#強化学習)
	1. [エージェント](#エージェント)
1. [能動学習](#能動学習)
1. [前処理](#前処理)
	1. [カテゴリデータ](#カテゴリデータ)
	1. [ラベルエンコーディング](#ラベルエンコーディング)
	1. [カウントエンコーディング](#カウントエンコーディング)
	1. [One-Hotエンコーディング](#one-hotエンコーディング)
	1. [離散化](#離散化)
	1. [対数変換](#対数変換)
	1. [スケーリング](#スケーリング)
1. [イテレーション](#イテレーション)
	1. [バッチ学習](#バッチ学習)
	1. [ミニバッチ学習](#ミニバッチ学習)
	1. [アウトオブコア学習](#アウトオブコア学習)
1. [データの分割](#データの分割)
	1. [訓練データ](#訓練データ)
	1. [検証データ](#検証データ)
	1. [テストデータ](#テストデータ)
	1. [ホールドアウト検証](#ホールドアウト検証)
	1. [クロスバリデーション](#クロスバリデーション)
	1. [Leave-one-out交差](#leave-one-out交差)
1. [損失関数](#損失関数)
	1. [決定係数](#決定係数)
	1. [平方二乗誤差](#平方二乗誤差)
	1. [平均絶対誤差](#平均絶対誤差)
	1. [クロスエントロピー誤差](#クロスエントロピー誤差)
1. [分類モデルの評価指標](#分類モデルの評価指標)
	1. [混合行列](#混合行列)
	1. [真陽性](#真陽性)
	1. [偽陰性](#偽陰性)
	1. [偽陽性](#偽陽性)
	1. [真陰性](#真陰性)
	1. [正解率](#正解率)
	1. [再現率](#再現率)
	1. [適合率](#適合率)
	1. [F値](#f値)
1. [ハイパーパラメータ](#ハイパーパラメータ)
	1. [未学習](#未学習)
	1. [過学習](#過学習)
	1. [オートチューニング](#オートチューニング)
	1. [グリッドサーチ](#グリッドサーチ)
	1. [ランダムサーチ](#ランダムサーチ)
	1. [焼きなまし法](#焼きなまし法)
	1. [ベイズ最適化](#ベイズ最適化)
	1. [遺伝的アルゴリズム](#遺伝的アルゴリズム)
1. [最適化問題](#最適化問題)


## 機械学習

**機械学習**(**ML**: Machine Learning)は、入力されたデータを元に、最も正しい振る舞いをする[パラメータ](#パラメータ)を自動的に学習する[人工知能](./artificial_intelligence.md#人工知能)。機械学習以前の[人工知能](./artificial_intelligence.md#人工知能)は、データを丸暗記するような学習が主流であったが、[パラメータ](#パラメータ)を用いて認識をする機械学習では、未知のデータに対しても対応できる。

### 学習モデル

**学習モデル**（**モデル**）は、[機械学習](#機械学習)を行う際の学習機の構成や、学習を行い[パラメータ](#パラメータ)を調整した後の学習機の状態を指す用語。データの[特徴量](#特徴量)を入力することで、何かしらの出力を行う。

### パラメータ

**パラメータ**は、[機械学習](#機械学習)において[モデル](#学習モデル)の振る舞いを決める基準となる値。

### チューニング

**チューニング**は、[パラメータ](#パラメータ)をより良い値へと更新することによって、[モデル](#学習モデル)の性能を向上させる処理。

### 特徴量

**特徴量**は、[モデル](#学習モデル)に入力されるデータの性質を表現する値:。分析する対象の見た目や匂い、触感などの様々な性質を表す情報を数値化したもので、[説明変数](../../../basics/applied_mathematics/_/chapters/probability_and_statistics.md#回帰分析)として用いられる。

### 学習率

**学習率**は、[モデル](#学習モデル)に対して学習の結果をどれほど反映させるか（[パラメータ](#パラメータ)をどれほど更新するか）という割合。学習率が高いと、新しいデータを学習しようとしたときに適応しやすくなる一方、古いデータの情報が失われやすくなる。

### 汎化性能

**汎化性能**は、[モデル](#学習モデル)の未知データに対する予測・分析性能。[モデル](#学習モデル)が学習データに対してどれだけ高い性能を持っていても、実際に[モデル](#学習モデル)を使用したい実場面において入力されるのは未知データであるため、汎化性能の高さが重要となる。

### 重み

**重み**は、[説明変数](../../../basics/applied_mathematics/_/chapters/probability_and_statistics.md#回帰分析)が[目的変数](../../../basics/applied_mathematics/_/chapters/probability_and_statistics.md#回帰分析)にどれほど影響しているかを表す係数。

### バイアス

**バイアス**は、[説明変数](../../../basics/applied_mathematics/_/chapters/probability_and_statistics.md#回帰分析)に関係なく[目的変数](../../../basics/applied_mathematics/_/chapters/probability_and_statistics.md#回帰分析)に影響を与える項。

### 分類

**分類**は、データが複数のグループのうちどれに属するかを判断する[モデル](#学習モデル)、あるいはそのような問題。入力されるデータがいくつかのグループに分類できることを前提として、グループ内でのデータの細かな違いは無視する。分類問題では、[モデル](#学習モデル)の出力は分類されるグループを表す離散値となる。

### 回帰

**回帰**は、データの傾向を見るための[モデル](#学習モデル)、あるいはそのような問題。入力されるデータを1つのグループとして見て、そのグループ内での違いを分析する。回帰では、[モデル](#学習モデル)の出力は連続値となる。

### クラス

**クラス**は、[分類](#分類)問題において、データが分類されるカテゴリやグループ。


## 教師あり学習

**教師あり学習**は、解決したいタスクの答えが含まれたデータを用いて、[モデル](#学習モデル)を学習させる[機械学習](#機械学習)の手法。この方法では、[モデル](#学習モデル)が出力する予測値と、[ラベル付きデータ](#ラベル付きデータ)の[ラベル](#ラベル)との誤差を小さくするように[パラメータ](#パラメータ)を調整していくことで学習を進める。

### ラベル

**ラベル**は、[教師あり学習](#教師あり学習)における学習データの答え。

### ラベル付きデータ

**ラベル付きデータ**は、[教師あり学習](#教師あり学習)に用いられる、[ラベル](#ラベル)が付与された学習データ。

### ラベリング

**ラベリング**（**アノテーション**）は、学習に用いたいデータに[ラベル](#ラベル)付けを行うことで、[ラベル付きデータ](#ラベル付きデータ)を作成する処理や作業。


## 教師なし学習

**教師なし学習**は、与えられたデータの本質的な構造や法則を抽出する方法。データの特徴を捉えることを目的としている。

### クラスタリング

**クラスタリング**は、データ群の中から特徴の似ているデータをグループ（クラスタ）ごとに分類するタスク。

### 階層的クラスタリング

**階層的クラスタリング**は、特徴の似ているクラスタ同士を1つずつ結合させていき、最終的に1つの大きなクラスタになるまで繰り返す方法。

### 非階層的クラスタリング

**非階層的クラスタリング**は、あらかじめ最終的なクラスタ数を決めておき、そのクラスタ数で最もよくデータを分類できるように[クラスタリング](#クラスタリング)する方法。

### 次元削減

**次元削減**は、データから重要な情報だけを抜き出して、重要度の低い情報を削減するタスク。ここで次元とは、[特徴量](#特徴量)の数を指す。4次元以上のデータを2次元や3次元に次元削減することによって、データの特徴を可視化することができるようになる。

### 次元の呪い

**次元の呪い**は、データの[特徴量](#特徴量)が多すぎることで、どの[特徴量](#特徴量)が重要であるかが判断できなくなり、[モデル](#学習モデル)の性能が悪くなる現象。


## 強化学習

**強化学習**は、[学習モデル](#学習モデル)に試行を繰り返させて、最適な行動を学習させる方法。[教師あり学習](#教師あり学習)のように明示的な正解があるわけではなく、[モデル](#学習モデル)がとった行動に対して報酬を与えることで、その報酬が高くなるような行動をするように仕向ける。

### エージェント

**エージェント**は、[強化学習](#強化学習)においてタスクに取り組む行動主体（プレイヤー）。


## 能動学習

**能動学習**は、教師データを闇雲に作って学習を行うのではなく、教師データの数を絞って学習を行う方法。あきらかに区別がつくデータではなく、紛らわしいデータに絞って[ラベリング](#ラベリング)を行うことで、ラベル付けのコストを抑えることができる。


## 前処理

**前処理**は、データを[機械学習](#機械学習)[モデル](#学習モデル)に入力する前に、データを加工したり整形したりする処理。

### カテゴリデータ

**カテゴリデータ**は、そのデータのカテゴリを表すもの。[コンピュータ](../../../computer/_/chapters/computer.md#コンピュータ)が扱いやすいように数値として表されるが、割り振られた番号は意味を持たず、大小を比較するといった数学的処理はできない。

### ラベルエンコーディング

**ラベルエンコーディング**は、各カテゴリにひとつの数字を割り当てる方法。

| ID | 都市   |
|----|--------|
| 1  | 東京   |
| 2  | 大阪   |
| 3  | 名古屋 |
| 4  | 大阪   |

| ID | 都市 |
|----|------|
| 1  | 1    |
| 2  | 2    |
| 3  | 3    |
| 4  | 2    |

### カウントエンコーディング

**カウントエンコーディング**は、その[カテゴリデータ](#カテゴリデータ)が出現した回数を割り当てる方法。

| ID | 都市   |
|----|--------|
| 1  | 東京   |
| 2  | 大阪   |
| 3  | 名古屋 |
| 4  | 大阪   |

| ID | 都市 |
|----|------|
| 1  | 1    |
| 2  | 2    |
| 3  | 1    |
| 4  | 2    |

### One-Hotエンコーディング

**One-Hotエンコーディング**は、列の名前をカテゴリ名にして、一致した列には1、それ以外の列には0を割り当てる方法。カテゴリの数だけ列の数が増える。

| ID | 都市   |
|----|--------|
| 1  | 東京   |
| 2  | 大阪   |
| 3  | 名古屋 |
| 4  | 大阪   |

| ID | 東京 | 大阪 | 名古屋 |
|----|------|------|--------|
| 1  | 1    | 0    | 0      |
| 2  | 0    | 1    | 0      |
| 3  | 0    | 0    | 1      |
| 4  | 0    | 1    | 0      |

### 離散化

**離散化**は、連続した値をある区分に分類する操作。データの持つ細かな性質の違いを吸収し、データを扱いやすくしたり、より意味のあるデータに変換したりする。

### 対数変換

**対数変換**は、データの[対数](../../../basics/applied_mathematics/_/chapters/numerical_calculation.md#対数)を取ることで、大きい値を持つデータを圧縮し、小さい値を持つデータを拡大することができる。

### スケーリング

**スケーリング**は、データのとり得る範囲を変換する操作。**Min-Maxスケーリング**では、データの最小値が0、最大値が1となるように、データのとり得る範囲を変換する。**標準化**では、値の平均が0、分散が1となるように、データのとり得る範囲を変換する。


## イテレーション

**イテレーション**は、モデルに学習データを繰り返し学習させることで、徐々に正しい出力ができるように調整していくこと。

### バッチ学習

**バッチ学習**（**オフライン学習**）は、1回の学習ですべての学習データを読み込む方法。一度に多くのデータを扱う必要があるため必要なメモリサイズが増加するが、すべてのデータを均等に扱える。

バッチ学習では、新しいデータをモデルに適用したい場合に、新旧データすべてを用いてモデルを学習し直さなければならず、リアルタイムでモデルを更新することが難しい。

### ミニバッチ学習

**ミニバッチ学習**（**オンライン学習**）は、1回の学習であらかじめ決めておいたバッチサイズ分、またはひとつの学習データを読み込む方法。最後の方に読み込んだデータの影響を受けやすいため、分割したデータを読み込む順序によってモデルの性能が変わる場合がある。また、バッチ学習に比べて計算回数が増加する。

ミニバッチ学習は、学習サイクルが速く、新しいデータを学習したい場合にも既存のモデルに対してすぐに適用できる。

### アウトオブコア学習

**アウトオブコア学習**は、データが大きすぎてバッチ学習が行えない場合に、データを小さな単位に分割した上で、オンライン学習のアルゴリズムを用いて学習を行う方法。


## データの分割

### 訓練データ

**訓練データ**は、モデルのパラメータを調整するための学習用データ。

### 検証データ

**検証データ**は、ハイパーパラメータのチューニングのためのデータで、学習には用いない。学習の途中で検証データによる性能の評価とハイパーパラメータの調整を繰り返していく。

### テストデータ

**テストデータ**は、モデルの汎化性能を測るために、学習が終了した後に用いる評価用データ。

### ホールドアウト検証

**ホールドアウト検証**は、データを学習用とテスト用データにある割合で分割する方法。学習データが膨大な場合に用いられることが多い。

### クロスバリデーション

**クロスバリデーション**（**K分割交差検証**）は、学習データとテストデータを入れ替えた複数の組み合わせを用意し、それらすべてで学習を行う方法。テストデータの偏りをなくしたり、不足している学習データ量を補ったりする目的で利用される。

### Leave-one-out交差

**Leave-one-out交差**は、全データから1つをテストデータとして抜き出し、残りのすべてを学習データとするような複数の組み合わせを用意して学習を行う方法。データ数に比例して計算量が増大するため、データ数が少ない場合にのみ利用される。


## 損失関数

**損失関数**（**コスト関数**、**誤差関数**）は、モデルを最適化するための指標となる関数。モデルが出力する予測値と、ラベル付きデータのラベルとの誤差を損失関数とする場合が多い。

### 決定係数

**決定係数**( $R^2$ )は、予測誤差を正規化することで得られる指標で、全く予測できていない場合を0、すべて予測できている場合を1として、大きいほどよい性能であることを表す。回帰問題の損失関数として用いられる。

### 平方二乗誤差

**平方二乗誤差**(**RMSE**)は、予測誤差を二乗して平均した後に平方を取る指標。正規分布の誤差に対して正確な評価ができるため、多くのケースで用いられる。回帰問題の損失関数として用いられる。

### 平均絶対誤差

**平均絶対誤差**(**MAE**)は、予測誤差の絶対値を二乗して平均した後に集計する指標。平均二乗誤差に比べて外れ地に強い。回帰問題の損失関数として用いられる。

### クロスエントロピー誤差

**クロスエントロピー誤差**（**交差エントロピー誤差**）は、分類問題において、モデルの出力したカテゴリの分布確立を元に、正解ラベルとの誤差を評価するための指標。分類問題の損失関数として用いられる。


## 分類モデルの評価指標

### 混合行列

**混合行列**は、2値分類問題において、モデルの出力と正解ラベルとの関係をまとめたマトリクス。データがとり得る値は真か偽の2値である。

### 真陽性

**真陽性**(**TP**: True Positive)は、混合行列において、正解が真であるデータに対してモデルの出力も真となった回数。

### 偽陰性

**偽陰性**(**FN**: False Negative)は、混合行列において、正解が真であるデータに対してモデルの出力が偽となった回数。

### 偽陽性

**偽陽性**(**FP**: False Positive)は、混合行列において、正解が偽であるデータに対してモデルの出力が真となった回数。

### 真陰性

**真陰性**(**TN**: True Negative)は、混合行列において、正解が偽であるデータに対してモデルの出力も偽となった回数。

### 正解率

**正解率**(Accuracy)は、全体のデータ数のうち正しく分類できたデータ数の割合。 $Accuracy = \frac{TP+TN}{TP+FP+FN+TN}$ で求められる。

### 再現率

**再現率**(Recall)は、実際に真であったデータのうち、正しく真と分類できたデータ数の割合。 $Recall = \frac{TP}{TP+FN}$ で求められる。病気の診断のように、偽陽性の数が増えることよりも、偽陰性の数が増えることが問題となるケースで用いられる。

### 適合率

**適合率**(Precision)は、真として分類したデータのうち、正しく分類できたデータ数の割合。 $Precision = \frac{TP}{TP+FP}$ で求められる。インターネットの検索エンジンのように、不要な情報を確実に取り除きたいケースで用いられる。

### F値

**F値**(f-score)は、再現率と適合率のトレードオフの関係にある値。 $f-score = \frac{2 \times Recall \times Precision}{Recall + Precision}$ で求められる。すべてのデータを真と判断すれば再現率は100%となるが、これは実用的であるとはいえない。F値は、一方が大きくなるともう一方が小さくなるため、より良い指標として用いられる。


## ハイパーパラメータ

**ハイパーパラメータ**は、モデルの持つパラメータの中で、学習によって調整されるものではなく、手動で決める必要があるもの。ただし、通常は人間が判断して決定することは非常に難しい。

###未学習

**未学習**は、十分に学習が行われていないことで、性能が低い状態。学習データに対する予測や分類の精度が十分に高くない場合は未学習であると言える。

### 過学習

**過学習**（**オーバフィッティング**）は、学習を過度に行いすぎることで、学習データに対しての精度は高いものの汎化性能が低くなってしまう状態。

### オートチューニング

**オートチューニング**は、ハイパーパラメータのチューニングを自動化するメカニズム。

### グリッドサーチ

**グリッドサーチ**は、すべてのハイパーパラメータの組み合わせの中で最も良いものを選択するオートチューニングの手法。ただし、候補の数が多くなると計算量が増大するため、モデルが複雑である場合には現実的ではない。

### ランダムサーチ

**ランダムサーチ**は、ハイパーパラメータの組み合わせをランダムに試行するオートチューニングの手法。

### 焼きなまし法

**焼きなまし法**（**疑似アニーリング**、**SA**）は、最初は様々なパターンを広く試行し、徐々に探す範囲を狭くしながらよい組み合わせを探索する方法。

### ベイズ最適化

**ベイズ最適化**は、ガウス過程という回帰モデルを利用したオートチューニングの手法。試しにいくつかの組み合わせで精度を計算し、その結果を元に、更に精度が高くなりそうなパラメータの候補を推定することで効率的に探索を行う。

### 遺伝的アルゴリズム

**遺伝的アルゴリズム**は、ハイパーパラメータの組み合わせを遺伝子とみなし、淘汰・交叉・突然変異などの処理を繰り返し行う（世代交代）ことで良い組み合わせを探索する手法。


## 最適化問題

**最適化問題**（**最適化**）は、目的関数が最小化あるいは最大化するような説明変数の組み合わせを求める問題。通常は目的関数の形がわかっていないため、説明変数に適当な値を入れてみてより良い値を探したり、これらの情報から目的関数の形を予測する。

説明変数の数が増えると、試行する組み合わせの数が爆発的に増加する（**組み合わせ爆発**）ため、最適化問題を解くための工夫を加えた**最適化アルゴリズム**が研究されている。

機械学習において最適なパラメータを求めることは、損失関数に関する最適化問題を解くことで、誤差を最小化するということである。損失関数は目的関数を予想して定義したものが用いられる。
