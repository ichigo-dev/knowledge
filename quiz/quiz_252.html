
<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8">
  <style>
   body
   {
       display: flex;
       justify-content: center;
       min-height: 100vh;
       background-color: #444;
       color: #fff;
   }

   .quiz_container
   {
       line-height: 2;
   }

   .mask
   {
       background-color: #fff;
       color: #fff;
       padding: 2px 8px;
       margin: 0 4px;
   }

   .mask.active
   {
       color: #000;
   }

   .btn_answer_container
   {
       text-align: center;
   }
  </style>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/kognise/water.css@latest/dist/dark.min.css">
 </head>
 <body>
  <div class="quiz_container">
   <p><p><strong>Transformer</strong>は、<a href="#attention">Attention</a>を応用した<strong><span class="mask">Self-Attention</span></strong>機構を持つ<a href="./neural_network.md#%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF">ニューラルネットワーク</a>の<a href="./machine_learning.md#%E5%AD%A6%E7%BF%92%E3%83%A2%E3%83%87%E3%83%AB">モデル</a>。<span class="mask">Self-Attention</span>は<a href="./neural_network.md#%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86">自然言語処理</a>のタスクにおいて、ある単語がその文章中のどの単語と結びつきが強いのか、という情報を明らかにするレイヤ。基本形は<a href="#seq2seq">Seq2Seq</a>と同様Encoder-Decoderの<a href="./machine_learning.md#%E5%AD%A6%E7%BF%92%E3%83%A2%E3%83%87%E3%83%AB">モデル</a>であるが、Encoderのみを取り出したものもある。</p>
</p>
   <div class="btn_answer_container">
    <button id="btn_answer" class="btn_answer">Show answer</button>
   </div>
  </div>

  <script>
   const btn_answer = document.getElementById("btn_answer");
   btn_answer.addEventListener("click", function()
   {
       const mask = document.querySelectorAll(".mask");
       mask.forEach(function(item)
       {
           item.classList.toggle("active");
       });
   });
  </script>
 </body>
</html>
            