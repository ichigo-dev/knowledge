# 『機械学習アルゴリズム』

（最終更新： 2023-02-12）


## 目次


## 回帰分析

**回帰分析**は、結果となる数値と要因となる数値の関係を調べて、それぞれの関係を明らかにする統計的手法。

説明したい変数を**目的変数**、それを予測するための変数を**説明変数**という。説明変数の係数を**重み**といい、これが回帰直線（曲線）への影響の大きさを決めるパラメータとなる。

### 単回帰

**単回帰**は、説明変数が1つである回帰モデル。直線的にデータを予測する最もシンプルな方法で、損失関数として平方二乗誤差を使用する**最小二乗法**が用いられる。

### 重回帰

**重回帰**は、説明変数が複数ある回帰モデル。複数の説明変数を用いることで、より複雑なモデルに対しても予測が行える。

### 多項式回帰

**多項式回帰**は、1つの説明変数のべき乗を組み合わせた多項式を用いる回帰モデル。字数が大きくなるほど曲線が複雑になり、不安定になってしまう。

### ロバスト回帰

**ロバスト回帰**は、外れ値の影響を小さくするような回帰モデル。最小二乗法の外れ値に弱いという欠点を克服することを目的としている。

**RANSAC**(Random Sample Consensus)はロバスト回帰の代表的な方法で、データをランダムに抽出して回帰を行い、正常値に当たるデータの割合を求める。これを繰り返して最も正常値の割合が高い直線を回帰直線とする。
