# 『機械学習』

（最終更新： 2023-02-12）


## 目次

1. [機械学習](#機械学習)
	1. [学習モデル](#学習モデル)
	1. [パラメータ](#パラメータ)
	1. [チューニング](#チューニング)
	1. [特徴量](#特徴量)
	1. [学習率](#学習率)
	1. [汎化性能](#汎化性能)
	1. [目的変数](#目的変数)
	1. [説明変数](#説明変数)
	1. [重み](#重み)
	1. [バイアス](#バイアス)
	1. [分類](#分類)
	1. [回帰](#回帰)
	1. [クラス](#クラス)
1. [教師あり学習](#教師あり学習)
	1. [ラベル](#ラベル)
	1. [ラベル付きデータ](#ラベル付きデータ)
	1. [ラベリング](#ラベリング)
1. [教師なし学習](#教師なし学習)
	1. [クラスタリング](#クラスタリング)
	1. [階層的クラスタリング](#階層的クラスタリング)
	1. [非階層的クラスタリング](#非階層的クラスタリング)
	1. [次元削減](#次元削減)
	1. [次元の呪い](#次元の呪い)
1. [強化学習](#強化学習)
	1. [エージェント](#エージェント)
1. [能動学習](#能動学習)
1. [前処理](#前処理)
	1. [カテゴリデータ](#カテゴリデータ)
	1. [ラベルエンコーディング](#ラベルエンコーディング)
	1. [カウントエンコーディング](#カウントエンコーディング)
	1. [One-Hotエンコーディング](#one-hotエンコーディング)
	1. [離散化](#離散化)
	1. [対数変換](#対数変換)
	1. [スケーリング](#スケーリング)
1. [イテレーション](#イテレーション)
	1. [バッチ学習](#バッチ学習)
	1. [ミニバッチ学習](#ミニバッチ学習)
	1. [アウトオブコア学習](#アウトオブコア学習)
1. [データの分割](#データの分割)
	1. [訓練データ](#訓練データ)
	1. [検証データ](#検証データ)
	1. [テストデータ](#テストデータ)
	1. [ホールドアウト検証](#ホールドアウト検証)
	1. [クロスバリデーション](#クロスバリデーション)
	1. [Leave-one-out交差](#leave-one-out交差)
1. [損失関数](#損失関数)
	1. [決定係数](#決定係数)
	1. [平方二乗誤差](#平方二乗誤差)
	1. [平均絶対誤差](#平均絶対誤差)
	1. [クロスエントロピー誤差](#クロスエントロピー誤差)
1. [分類モデルの評価指標](#分類モデルの評価指標)
	1. [混合行列](#混合行列)
	1. [真陽性](#真陽性)
	1. [偽陰性](#偽陰性)
	1. [偽陽性](#偽陽性)
	1. [真陰性](#真陰性)
	1. [正解率](#正解率)
	1. [再現率](#再現率)
	1. [適合率](#適合率)
	1. [F値](#f値)
1. [ハイパーパラメータ](#ハイパーパラメータ)
	1. [未学習](#未学習)
	1. [過学習](#過学習)
	1. [オートチューニング](#オートチューニング)
	1. [グリッドサーチ](#グリッドサーチ)
	1. [ランダムサーチ](#ランダムサーチ)
	1. [焼きなまし法](#焼きなまし法)
	1. [ベイズ最適化](#ベイズ最適化)
	1. [遺伝的アルゴリズム](#遺伝的アルゴリズム)
1. [最適化問題](#最適化問題)


## 機械学習

**機械学習**(**ML**: Machine Learning)は、入力されたデータを元に、最も正しい振る舞いをするパラメータを自動的に学習する人工知能。機械学習以前の人工知能は、データを丸暗記するような学習が主流であったが、パラメータを用いて認識をする機械学習では、未知のデータに対しても対応できる。

### 学習モデル

**学習モデル**（**モデル**）は、機械学習を行う際の学習機の構成や、学習を行いパラメータを調整した後の学習機の状態のこと。データの特徴量を入力することで、何かしらの出力を行う。

### パラメータ

**パラメータ**は、機械学習においてモデルの振る舞いを決める基準となる値。

### チューニング

**チューニング**は、パラメータをより良い値へと更新することによって、モデルの性能を向上させること。

### 特徴量

**特徴量**は、モデルに入力されるデータの性質を表現する値。分析する対象の見た目や匂い、触感などの様々な性質を表す情報を数値化したもの。

### 学習率

**学習率**は、モデルに対して学習の結果をどれほど反映させるかという割合。学習率が高いと、新しいデータを学習しようとしたときに適応しやすくなる一方、古いデータの情報が失われやすくなる。

### 汎化性能

**汎化性能**は、モデルの未知データに対する予測・分析性能のこと。モデルが学習データに対してどれだけ高い性能を持っていても、実際にモデルを使用したい実場面において入力されるのは未知データであるため、汎化性能の高さが重要となる。

### 目的変数

**目的変数**は、予測したい変数。

### 説明変数

**説明変数**は、目的変数を予測するための変数。機械学習においては特徴量が説明変数となる。

### 重み

**重み**は、説明変数が目的変数にどれほど影響しているかを表す係数。

### バイアス

**バイアス**は、説明変数に関係なく目的変数に影響を与える項。

### 分類

**分類**は、データが複数のグループのうちどれに属するかを判断するモデル、あるいはそのような問題。入力されるデータがいくつかのグループに分類できることを前提として、グループ内でのデータの細かな違いは無視する。分類問題では、モデルの出力は分類されるグループを表す離散値となる。

### 回帰

**回帰**は、データの傾向を見るためのモデル、あるいはそのような問題。入力されるデータを1つのグループとして見て、そのグループ内での違いを分析する。回帰では、モデルの出力は連続値となる。

### クラス

**クラス**は、分類問題において、データが分類されるカテゴリやグループのこと。


## 教師あり学習

**教師あり学習**は、正解となる答えが含まれたデータを用いて、モデルを学習させる方法。この方法では、モデルが出力する予測値と、ラベル付きデータのラベルとの誤差を小さくするようにパラメータを調整していくことで学習を進める。

### ラベル

**ラベル**は、教師あり学習において、データの答えのこと。

### ラベル付きデータ

**ラベル付きデータ**は、教師あり学習に用いられる、ラベルが付与された学習データのこと。

### ラベリング

**ラベリング**（**アノテーション**）は、学習に用いたいデータにラベル付けを行うことで、ラベル付きデータを作成すること。


## 教師なし学習

**教師なし学習**は、与えられたデータの本質的な構造や法則を抽出する方法。データの特徴を捉えることを目的としている。

### クラスタリング

**クラスタリング**は、データ群の中から特徴の似ているデータをグループ（クラスタ）ごとに分類するタスク。

### 階層的クラスタリング

**階層的クラスタリング**は、特徴の似ているクラスタ同士を1つずつ結合させていき、最終的に1つの大きなクラスタになるまで繰り返す方法。

### 非階層的クラスタリング

**非階層的クラスタリング**は、あらかじめ最終的なクラスタ数を決めておき、そのクラスタ数で最もよくデータを分類できるようにクラスタリングする方法。

### 次元削減

**次元削減**は、データから重要な情報だけを抜き出して、重要度の低い情報を削減するタスク。ここで次元とは、特徴量の数のこと。4次元以上のデータを2次元や3次元に次元削減することによって、データの特徴を可視化することができるようになる。

### 次元の呪い

**次元の呪い**は、データの特徴量が多すぎることで、どの特徴量が重要であるかが判断できなくなり、モデルの性能が悪くなること。


## 強化学習

**強化学習**は、学習モデルに試行を繰り返させて、最適な行動を学習させる方法。教師あり学習のように明示的な正解があるわけではなく、モデルがとった行動に対して報酬を与えることで、その報酬が高くなるような行動をするように仕向ける。

### エージェント

**エージェント**は、強化学習においてタスクに取り組む、プレイヤーなどの行動主体のこと。


## 能動学習

**能動学習**は、教師データを闇雲に作って学習を行うのではなく、教師データの数を絞って学習を行う方法。あきらかに区別がつくデータではなく、紛らわしいデータに絞ってラベリングを行うことで、ラベル付けのコストを抑えることができる。


## 前処理

**前処理**は、データを機械学習モデルに入力する前に、データを加工したり整形したりすること。

### カテゴリデータ

**カテゴリデータ**は、そのデータのカテゴリを表すもの。コンピュータが扱いやすいように数値として表されるが、割り振られた番号は意味を持たず、大小を比較するといった数学的処理はできない。

### ラベルエンコーディング

**ラベルエンコーディング**は、各カテゴリにひとつの数字を割り当てる方法。

| ID | 都市   |
|----|--------|
| 1  | 東京   |
| 2  | 大阪   |
| 3  | 名古屋 |
| 4  | 大阪   |

| ID | 都市 |
|----|------|
| 1  | 1    |
| 2  | 2    |
| 3  | 3    |
| 4  | 2    |

### カウントエンコーディング

**カウントエンコーディング**は、そのカテゴリデータが出現した回数を割り当てる方法。

| ID | 都市   |
|----|--------|
| 1  | 東京   |
| 2  | 大阪   |
| 3  | 名古屋 |
| 4  | 大阪   |

| ID | 都市 |
|----|------|
| 1  | 1    |
| 2  | 2    |
| 3  | 1    |
| 4  | 2    |

### One-Hotエンコーディング

**One-Hotエンコーディング**は、列の名前をカテゴリ名にして、一致した列には1、それ以外の列には0を割り当てる方法。カテゴリの数だけ列の数が増える。

| ID | 都市   |
|----|--------|
| 1  | 東京   |
| 2  | 大阪   |
| 3  | 名古屋 |
| 4  | 大阪   |

| ID | 東京 | 大阪 | 名古屋 |
|----|------|------|--------|
| 1  | 1    | 0    | 0      |
| 2  | 0    | 1    | 0      |
| 3  | 0    | 0    | 1      |
| 4  | 0    | 1    | 0      |

### 離散化

**離散化**は、連続した値をある区分に分類する操作。データの持つ細かな性質の違いを吸収し、データを扱いやすくしたり、より意味のあるデータに変換したりする。

### 対数変換

**対数変換**は、データの対数を取ることで、大きい値を持つデータを圧縮し、小さい値を持つデータを拡大することができる。

### スケーリング

**スケーリング**は、データのとり得る範囲を変換する操作。**Min-Maxスケーリング**では、データの最小値が0、最大値が1となるように、データのとり得る範囲を変換する。**標準化**では、値の平均が0、分散が1となるように、データのとり得る範囲を変換する。


## イテレーション

**イテレーション**は、モデルに学習データを繰り返し学習させることで、徐々に正しい出力ができるように調整していくこと。

### バッチ学習

**バッチ学習**（**オフライン学習**）は、1回の学習ですべての学習データを読み込む方法。一度に多くのデータを扱う必要があるため必要なメモリサイズが増加するが、すべてのデータを均等に扱える。

バッチ学習では、新しいデータをモデルに適用したい場合に、新旧データすべてを用いてモデルを学習し直さなければならず、リアルタイムでモデルを更新することが難しい。

### ミニバッチ学習

**ミニバッチ学習**（**オンライン学習**）は、1回の学習であらかじめ決めておいたバッチサイズ分、またはひとつの学習データを読み込む方法。最後の方に読み込んだデータの影響を受けやすいため、分割したデータを読み込む順序によってモデルの性能が変わる場合がある。また、バッチ学習に比べて計算回数が増加する。

ミニバッチ学習は、学習サイクルが速く、新しいデータを学習したい場合にも既存のモデルに対してすぐに適用できる。

### アウトオブコア学習

**アウトオブコア学習**は、データが大きすぎてバッチ学習が行えない場合に、データを小さな単位に分割した上で、オンライン学習のアルゴリズムを用いて学習を行う方法。


## データの分割

### 訓練データ

**訓練データ**は、モデルのパラメータを調整するための学習用データ。

### 検証データ

**検証データ**は、ハイパーパラメータのチューニングのためのデータで、学習には用いない。学習の途中で検証データによる性能の評価とハイパーパラメータの調整を繰り返していく。

### テストデータ

**テストデータ**は、モデルの汎化性能を測るために、学習が終了した後に用いる評価用データ。

### ホールドアウト検証

**ホールドアウト検証**は、データを学習用とテスト用データにある割合で分割する方法。学習データが膨大な場合に用いられることが多い。

### クロスバリデーション

**クロスバリデーション**（**K分割交差検証**）は、学習データとテストデータを入れ替えた複数の組み合わせを用意し、それらすべてで学習を行う方法。テストデータの偏りをなくしたり、不足している学習データ量を補ったりする目的で利用される。

### Leave-one-out交差

**Leave-one-out交差**は、全データから1つをテストデータとして抜き出し、残りのすべてを学習データとするような複数の組み合わせを用意して学習を行う方法。データ数に比例して計算量が増大するため、データ数が少ない場合にのみ利用される。


## 損失関数

**損失関数**（**コスト関数**、**誤差関数**）は、モデルを最適化するための指標となる関数。モデルが出力する予測値と、ラベル付きデータのラベルとの誤差を損失関数とする場合が多い。

### 決定係数

**決定係数**( $R^2$ )は、予測誤差を正規化することで得られる指標で、全く予測できていない場合を0、すべて予測できている場合を1として、大きいほどよい性能であることを表す。回帰問題の損失関数として用いられる。

### 平方二乗誤差

**平方二乗誤差**(**RMSE**)は、予測誤差を二乗して平均した後に平方を取る指標。正規分布の誤差に対して正確な評価ができるため、多くのケースで用いられる。回帰問題の損失関数として用いられる。

### 平均絶対誤差

**平均絶対誤差**(**MAE**)は、予測誤差の絶対値を二乗して平均した後に集計する指標。平均二乗誤差に比べて外れ地に強い。回帰問題の損失関数として用いられる。

### クロスエントロピー誤差

**クロスエントロピー誤差**（**交差エントロピー誤差**）は、分類問題において、モデルの出力したカテゴリの分布確立を元に、正解ラベルとの誤差を評価するための指標。分類問題の損失関数として用いられる。


## 分類モデルの評価指標

### 混合行列

**混合行列**は、2値分類問題において、モデルの出力と正解ラベルとの関係をまとめたマトリクス。データがとり得る値は真か偽の2値である。

### 真陽性

**真陽性**(**TP**: True Positive)は、混合行列において、正解が真であるデータに対してモデルの出力も真となった回数。

### 偽陰性

**偽陰性**(**FN**: False Negative)は、混合行列において、正解が真であるデータに対してモデルの出力が偽となった回数。

### 偽陽性

**偽陽性**(**FP**: False Positive)は、混合行列において、正解が偽であるデータに対してモデルの出力が真となった回数。

### 真陰性

**真陰性**(**TN**: True Negative)は、混合行列において、正解が偽であるデータに対してモデルの出力も偽となった回数。

### 正解率

**正解率**(Accuracy)は、全体のデータ数のうち正しく分類できたデータ数の割合。 $Accuracy = \frac{TP+TN}{TP+FP+FN+TN}$ で求められる。

### 再現率

**再現率**(Recall)は、実際に真であったデータのうち、正しく真と分類できたデータ数の割合。 $Recall = \frac{TP}{TP+FN}$ で求められる。病気の診断のように、偽陽性の数が増えることよりも、偽陰性の数が増えることが問題となるケースで用いられる。

### 適合率

**適合率**(Precision)は、真として分類したデータのうち、正しく分類できたデータ数の割合。 $Precision = \frac{TP}{TP+FP}$ で求められる。インターネットの検索エンジンのように、不要な情報を確実に取り除きたいケースで用いられる。

### F値

**F値**(f-score)は、再現率と適合率のトレードオフの関係にある値。 $f-score = \frac{2 \times Recall \times Precision}{Recall + Precision}$ で求められる。すべてのデータを真と判断すれば再現率は100%となるが、これは実用的であるとはいえない。F値は、一方が大きくなるともう一方が小さくなるため、より良い指標として用いられる。


## ハイパーパラメータ

**ハイパーパラメータ**は、モデルの持つパラメータの中で、学習によって調整されるものではなく、手動で決める必要があるもの。ただし、通常は人間が判断して決定することは非常に難しい。

###未学習

**未学習**は、十分に学習が行われていないことで、性能が低い状態。学習データに対する予測や分類の精度が十分に高くない場合は未学習であると言える。

### 過学習

**過学習**（**オーバフィッティング**）は、学習を過度に行いすぎることで、学習データに対しての精度は高いものの汎化性能が低くなってしまう状態。

### オートチューニング

**オートチューニング**は、ハイパーパラメータのチューニングを自動化するメカニズム。

### グリッドサーチ

**グリッドサーチ**は、すべてのハイパーパラメータの組み合わせの中で最も良いものを選択するオートチューニングの手法。ただし、候補の数が多くなると計算量が増大するため、モデルが複雑である場合には現実的ではない。

### ランダムサーチ

**ランダムサーチ**は、ハイパーパラメータの組み合わせをランダムに試行するオートチューニングの手法。

### 焼きなまし法

**焼きなまし法**（**疑似アニーリング**、**SA**）は、最初は様々なパターンを広く試行し、徐々に探す範囲を狭くしながらよい組み合わせを探索する方法。

### ベイズ最適化

**ベイズ最適化**は、ガウス過程という回帰モデルを利用したオートチューニングの手法。試しにいくつかの組み合わせで精度を計算し、その結果を元に、更に精度が高くなりそうなパラメータの候補を推定することで効率的に探索を行う。

### 遺伝的アルゴリズム

**遺伝的アルゴリズム**は、ハイパーパラメータの組み合わせを遺伝子とみなし、淘汰・交叉・突然変異などの処理を繰り返し行う（世代交代）ことで良い組み合わせを探索する手法。


## 最適化問題

**最適化問題**（**最適化**）は、目的関数が最小化あるいは最大化するような説明変数の組み合わせを求める問題。通常は目的関数の形がわかっていないため、説明変数に適当な値を入れてみてより良い値を探したり、これらの情報から目的関数の形を予測する。

説明変数の数が増えると、試行する組み合わせの数が爆発的に増加する（**組み合わせ爆発**）ため、最適化問題を解くための工夫を加えた**最適化アルゴリズム**が研究されている。

機械学習において最適なパラメータを求めることは、損失関数に関する最適化問題を解くことで、誤差を最小化するということである。損失関数は、本来の目的関数を予想したものといえる。
